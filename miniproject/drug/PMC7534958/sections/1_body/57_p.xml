<?xml version="1.0" encoding="UTF-8"?>
<p>Beck et al. used a natural language processing (NLP)-based approach to estimate the binding affinity of 3,410 FDA-approved drugs against potential targets of SARS-CoV-2, including 3CL
 <sup>pro</sup>, S protein, RdRP, helicase, endoRNAse, 3’-to-5’- exonuclease and 2’-O-ribose methyltransferase.
 <xref rid="B103" ref-type="bibr">
  <sup>103</sup>
 </xref> The premise of their approach is analogous to understanding text in different languages, for instance by learning the semantic relationships of words to execute a task, such as predicting the most probable word in a text or the sentiment expressed by it.
 <xref rid="B180" ref-type="bibr">
  <sup>180</sup>
 </xref>
 <sup>,</sup>
 <xref rid="B181" ref-type="bibr">
  <sup>181</sup>
 </xref>
 <sup>,</sup>
 <xref rid="B182" ref-type="bibr">
  <sup>182</sup>
 </xref>⁠ Their model, called molecular transformer-drug target interaction (MT-DTI) was trained on 1 billion SMILES strings and the FASTA sequence of target proteins, which bypass the need for 3D structures (e.g., X-ray) of protein-target complexes.
 <xref rid="B183" ref-type="bibr">
  <sup>183</sup>
 </xref>⁠ The pre-training approach allows the model to be used for other related tasks without the need to train from scratch, which is especially important when not enough data is available, which is the case for SARS-CoV-2 inhibitors. In addition, this approach is able to transfer more general features learned by the model, making it extremely flexible to deal with related tasks.
 <xref rid="B184" ref-type="bibr">
  <sup>184</sup>
 </xref>
 <sup>,</sup>
 <xref rid="B185" ref-type="bibr">
  <sup>185</sup>
 </xref>
</p>
