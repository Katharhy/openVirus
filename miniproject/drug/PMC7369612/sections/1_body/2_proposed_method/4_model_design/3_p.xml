<?xml version="1.0" encoding="UTF-8"?>
<p id="p0032">In all our experiments, we train the LSTM for 10,000 epochs with 10 layers and a batch size of 10. All normalization is performed on the 
 <italic>log</italic> scale and Adam 
 <xref rid="bib0039" ref-type="bibr">[39]</xref> is used as the optimizer with a learning rate of 0.001. The window parameters we specifically focus on in this case are the 
 <italic>lookback</italic> and 
 <italic>lookahead</italic> parameters which are tuned based on the data of a particular location. In this case, the 
 <italic>lookback</italic> parameter is indicative of the window size in terms of the number of consecutive days the LSTM needs to “look back” at in order to make a reasonable prediction. The 
 <italic>lookahead</italic> parameter indicates the number of days in advance that the system needs to “look ahead” in order to make a prediction for a future date. Both the 
 <italic>lookback</italic> and 
 <italic>lookahead</italic> parameters are used by carrying out index slicing on the respective training, validation, and test data and can be formulated as data[:-(
 <italic>lookahead</italic>)] split into sets of 
 <italic>lookback</italic> days based on time for the model input and data[(
 <inline-formula>
  <math id="M1" altimg="si1.svg">
   <mrow>
    <mi>l</mi>
    <mi>o</mi>
    <mi>o</mi>
    <mi>k</mi>
    <mi>b</mi>
    <mi>a</mi>
    <mi>c</mi>
    <mi>k</mi>
    <mspace width="0.16em"/>
    <mo linebreak="goodbreak">+</mo>
    <mspace width="0.16em"/>
    <mi>l</mi>
    <mi>o</mi>
    <mi>o</mi>
    <mi>k</mi>
    <mi>a</mi>
    <mi>h</mi>
    <mi>e</mi>
    <mi>a</mi>
    <mi>d</mi>
   </mrow>
  </math>
 </inline-formula>):] for the model output.
</p>
